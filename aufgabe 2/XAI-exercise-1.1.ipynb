{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0b5585a",
   "metadata": {},
   "source": [
    "# 1 Task: Importance of Explainable Artificial Intelligence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc891e4c",
   "metadata": {},
   "source": [
    "### a. What is Explainable Artificial Intelligence (XAI)?\n",
    "\n",
    "#### Definitions:\n",
    "\n",
    "- **General Definition**:  \n",
    "  \"Explainable AI (XAI) focuses on developing methods and frameworks to enhance the **interpretability** and **transparency** of AI models, bridging the gap between **accuracy** and **explainability**.\"\n",
    "  — *[Mihály Héder, 2023: \"Explainable AI: A Brief History of the Concept\"]*\n",
    "\n",
    "- **Interpretability**:  \n",
    "  > \"Interpretability is the degree to which a human can understand the cause of a decision.\"  \n",
    "  — *(Biran and Cotton, 2017)*\n",
    "\n",
    "- **DARPA Definition**:  \n",
    "  Explainable AI refers to AI systems that:\n",
    "  - Can **explain their rationale** to a human user,\n",
    "  - **Characterize their strengths and weaknesses**,\n",
    "  - **Convey an understanding** of how they will behave in the future.  \n",
    "  — *[DARPA’s Explainable Artificial Intelligence Program — David Gunning, David W. Aha]*\n",
    "\n",
    "##### Own Definition:\n",
    "Explainable AI is a field of artificial intelligence that focuses on **methods** and **techniques** which aim to make AI systems and their **decisions**, its **causes**, and **results** understandable to humans (experts).\n",
    "(inspired by https://www.ibm.com/think/topics/explainable-ai and AI generated definitions)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92b0d4b",
   "metadata": {},
   "source": [
    "### b. What are potential problems of black box machine learning models (in general)?\n",
    "\n",
    "Based on Rundi, C. (2019)  \"Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead.\" \"A black box model is a function that is ...\n",
    "- i) ... to complicated for any human to comprehend\n",
    "- ii) ..  proprietary, we simply dont have insights to internal functionality\n",
    "\n",
    "- iii) Explanation =/ Understanding reality: If we try to explain them, we just replicate model behaviour not real-world logic + explanations are untrustable (bc every model has an error rate)\n",
    "- iv) BBM struggle when decisions require data/information outside of the dataset/database used of the model\n",
    "\n",
    "- v) Biases and Fariness Issues: Hidden biases could exist -> hard to detect those\n",
    "- vi) vulnerable to adversarial attacks: BBM can be highly sensitive to small perturbations, e.g image recognition\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7be9a4",
   "metadata": {},
   "source": [
    "### c. What are applications of explainable artificial intelligence?\n",
    "\n",
    "### 1. XAI in Agriculture\n",
    "**Source**: AgroXAI: Explainable AI-Driven Crop Recommendation System for Agriculture 4.0 by Ozlem Turgut, Ibrahim Kok, Suat Ozdemir\n",
    "- AgroXAI recommends suitable crops for specific regions  based on weather and soil conditions. Applies XAI to provide global and local explanations for recommendations\n",
    "- Can be used by farmers to get crop recommendations and undrestand rationale behind those to improve farming practices (e.g use X crops with Y pestizides and Z irrigation becasue of ...)\n",
    "\n",
    "### 2. XAI in Cybersecurity: Real-Time Threat Detection in Edge Networks\n",
    "**Source**: Gerald Fahner, “Rahmati, M. (2025). Towards Explainable and Lightweight AI for Real-Time Cyber Threat Hunting in Edge Networks\", Milad Rahmati \n",
    "- realtime XAI framwork for threat detection with explanations.\n",
    "- helps security analysts to interpret decisions of AI system thourgh clear explanations for threat detections\n",
    "- enables security staff to mitigagte threats more effectively\n",
    "\n",
    "\n",
    "### 3. XAI in Education\n",
    "**Source**: \"Human-Centric eXplainable AI in Education\", by Subhankar Maity, Aniket Deroy\n",
    "- AI becomes more integrated in education environments\n",
    "- XAI approaches assist in analyzing stundents performance and provide personalized feedback. XAI systems can give recommendations incl. the resoning behind\n",
    "- Educators can adapt their teching, students recive clear feedback with explanation -> helps deteciing learning problems and their causes + advancements\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
